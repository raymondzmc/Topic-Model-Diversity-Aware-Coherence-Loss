{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines.cetopictm import CETopicTM\n",
    "\n",
    "from utils import prepare_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset from Raymond's code\n",
    "\n",
    "#20News Groups\n",
    "\n",
    "text_file = 'resources/20news_unprep.txt'\n",
    "bow_file = 'resources/20news_prep.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, sentences = prepare_dataset('bbc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 2225\n"
     ]
    }
   ],
   "source": [
    "print('Number of sentences: {}'.format(len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed number: 852\n",
      "Initialize CETopicTM with num_topics=20, embedding=/mnt/datasets/SBERT/all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "random_seed_number = random.randint(0, 1000)\n",
    "print('Random seed number: {}'.format(random_seed_number))\n",
    "\n",
    "\n",
    "tm = CETopicTM(dataset=dataset, \n",
    "               topic_model='cetopic', \n",
    "               num_topics=20, \n",
    "               dim_size=50,#In the paper the authors say 'we reduce the dimensionality of sentence embedding to 50 usign UMAP' #default 5 \n",
    "               word_select_method='tfidf_idfi', #best word selection method according to their paper\n",
    "               embedding='/mnt/datasets/SBERT/all-mpnet-base-v2',\n",
    "               seed=random_seed_number)  #sentence-transformers/all-mpnet-base-v2', #embedding='princeton-nlp/unsup-simcse-bert-base-uncased',  #Default in Raymond's evaluation is: all-mpnet-base-v2 #TODO: I think we must use a different embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tm\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/mnt/felipe/semantic-aware-contextualized-topic-models/baseline_comparison/topicx/baselines/cetopictm.py:32\u001b[0m, in \u001b[0;36mCETopicTM.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtopics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit_transform(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentences)\n",
      "File \u001b[0;32m/mnt/felipe/semantic-aware-contextualized-topic-models/baseline_comparison/topicx/baselines/cetopic/cetopic.py:55\u001b[0m, in \u001b[0;36mCETopic.fit_transform\u001b[0;34m(self, documents, embeddings)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m embeddings \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model \u001b[39m=\u001b[39m select_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model)\n\u001b[0;32m---> 55\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_embeddings(documents\u001b[39m.\u001b[39;49mDocument)\n\u001b[1;32m     56\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/felipe/semantic-aware-contextualized-topic-models/baseline_comparison/topicx/baselines/cetopic/cetopic.py:84\u001b[0m, in \u001b[0;36mCETopic._extract_embeddings\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_extract_embeddings\u001b[39m(\u001b[39mself\u001b[39m, documents):\n\u001b[0;32m---> 84\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_model\u001b[39m.\u001b[39;49membed_documents(documents)\n\u001b[1;32m     86\u001b[0m     \u001b[39mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m/mnt/felipe/semantic-aware-contextualized-topic-models/baseline_comparison/topicx/baselines/cetopic/backend/_base.py:69\u001b[0m, in \u001b[0;36mBaseEmbedder.embed_documents\u001b[0;34m(self, document, verbose)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_documents\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     56\u001b[0m                     document: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m     57\u001b[0m                     verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     58\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Embed a list of n words into an n-dimensional\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m    matrix of embeddings\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39m        that each have an embeddings size of `m`\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed(document, verbose)\n",
      "File \u001b[0;32m/mnt/felipe/semantic-aware-contextualized-topic-models/baseline_comparison/topicx/baselines/cetopic/backend/_flair.py:71\u001b[0m, in \u001b[0;36mFlairBackend.embed\u001b[0;34m(self, documents, verbose)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     sentence \u001b[39m=\u001b[39m Sentence(document) \u001b[39mif\u001b[39;00m document \u001b[39melse\u001b[39;00m Sentence(\u001b[39m\"\u001b[39m\u001b[39man empty document\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_model\u001b[39m.\u001b[39;49membed(sentence)\n\u001b[1;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     sentence \u001b[39m=\u001b[39m Sentence(\u001b[39m\"\u001b[39m\u001b[39man empty document\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/felipe/.raymond/lib/python3.8/site-packages/flair/embeddings/base.py:49\u001b[0m, in \u001b[0;36mEmbeddings.embed\u001b[0;34m(self, data_points)\u001b[0m\n\u001b[1;32m     46\u001b[0m     data_points \u001b[39m=\u001b[39m [data_points]\n\u001b[1;32m     48\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_everything_embedded(data_points):\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_embeddings_internal(data_points)\n\u001b[1;32m     51\u001b[0m \u001b[39mreturn\u001b[39;00m data_points\n",
      "File \u001b[0;32m/mnt/felipe/.raymond/lib/python3.8/site-packages/flair/embeddings/transformer.py:656\u001b[0m, in \u001b[0;36mTransformerBaseEmbeddings._add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    654\u001b[0m gradient_context \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39menable_grad() \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfine_tune \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining) \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad()\n\u001b[1;32m    655\u001b[0m \u001b[39mwith\u001b[39;00m gradient_context:\n\u001b[0;32m--> 656\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_tensors(tensors)\n\u001b[1;32m    658\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocument_embedding:\n\u001b[1;32m    659\u001b[0m     document_embedding \u001b[39m=\u001b[39m embeddings[\u001b[39m\"\u001b[39m\u001b[39mdocument_embeddings\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/mnt/felipe/.raymond/lib/python3.8/site-packages/flair/embeddings/transformer.py:1313\u001b[0m, in \u001b[0;36mTransformerEmbeddings._forward_tensors\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_tensors\u001b[39m(\u001b[39mself\u001b[39m, tensors) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m-> 1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtensors)\n",
      "File \u001b[0;32m/mnt/felipe/.raymond/lib/python3.8/site-packages/flair/embeddings/transformer.py:1217\u001b[0m, in \u001b[0;36mTransformerEmbeddings.forward\u001b[0;34m(self, input_ids, sub_token_lengths, token_lengths, attention_mask, overflow_to_sample_mapping, word_ids, langs, bbox, pixel_values)\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[39mif\u001b[39;00m pixel_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1216\u001b[0m     model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mpixel_values\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pixel_values\n\u001b[0;32m-> 1217\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(input_ids, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m   1218\u001b[0m \u001b[39m# make the tuple a tensor; makes working with it easier.\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m hidden_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(hidden_states)\n",
      "File \u001b[0;32m/mnt/felipe/.raymond/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/felipe/.raymond/lib/python3.8/site-packages/transformers/models/mpnet/modeling_mpnet.py:552\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    551\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(input_ids\u001b[39m=\u001b[39minput_ids, position_ids\u001b[39m=\u001b[39mposition_ids, inputs_embeds\u001b[39m=\u001b[39minputs_embeds)\n\u001b[0;32m--> 552\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    553\u001b[0m     embedding_output,\n\u001b[1;32m    554\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    555\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    556\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    557\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    558\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    559\u001b[0m )\n\u001b[1;32m    560\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    561\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/felipe/.raymond/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/felipe/.raymond/lib/python3.8/site-packages/transformers/models/mpnet/modeling_mpnet.py:333\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    324\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    325\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    332\u001b[0m ):\n\u001b[0;32m--> 333\u001b[0m     position_bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_position_bias(hidden_states)\n\u001b[1;32m    334\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m () \u001b[39mif\u001b[39;00m output_hidden_states \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     all_attentions \u001b[39m=\u001b[39m () \u001b[39mif\u001b[39;00m output_attentions \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/felipe/.raymond/lib/python3.8/site-packages/transformers/models/mpnet/modeling_mpnet.py:376\u001b[0m, in \u001b[0;36mMPNetEncoder.compute_position_bias\u001b[0;34m(self, x, position_ids, num_buckets)\u001b[0m\n\u001b[1;32m    372\u001b[0m     memory_position \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(klen, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)[\u001b[39mNone\u001b[39;00m, :]\n\u001b[1;32m    374\u001b[0m relative_position \u001b[39m=\u001b[39m memory_position \u001b[39m-\u001b[39m context_position\n\u001b[0;32m--> 376\u001b[0m rp_bucket \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrelative_position_bucket(relative_position, num_buckets\u001b[39m=\u001b[39;49mnum_buckets)\n\u001b[1;32m    377\u001b[0m rp_bucket \u001b[39m=\u001b[39m rp_bucket\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    378\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelative_attention_bias(rp_bucket)\n",
      "File \u001b[0;32m/mnt/felipe/.raymond/lib/python3.8/site-packages/transformers/models/mpnet/modeling_mpnet.py:389\u001b[0m, in \u001b[0;36mMPNetEncoder.relative_position_bucket\u001b[0;34m(relative_position, num_buckets, max_distance)\u001b[0m\n\u001b[1;32m    386\u001b[0m n \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mrelative_position\n\u001b[1;32m    388\u001b[0m num_buckets \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m--> 389\u001b[0m ret \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (n \u001b[39m<\u001b[39;49m \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mto(torch\u001b[39m.\u001b[39;49mlong) \u001b[39m*\u001b[39;49m num_buckets\n\u001b[1;32m    390\u001b[0m n \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mabs(n)\n\u001b[1;32m    392\u001b[0m max_exact \u001b[39m=\u001b[39m num_buckets \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tm.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/13/2023 13:26:40 - INFO - gensim.corpora.dictionary -   adding document #0 to Dictionary<0 unique tokens: []>\n",
      "03/13/2023 13:26:40 - INFO - gensim.corpora.dictionary -   built Dictionary<2949 unique tokens: ['abandon', 'abroad', 'absence', 'absolute', 'absolutely']...> from 20 documents (total 267259 corpus positions)\n",
      "03/13/2023 13:26:40 - INFO - gensim.utils -   Dictionary lifecycle event {'msg': \"built Dictionary<2949 unique tokens: ['abandon', 'abroad', 'absence', 'absolute', 'absolutely']...> from 20 documents (total 267259 corpus positions)\", 'datetime': '2023-03-13T13:26:40.263885', 'gensim': '4.2.0', 'python': '3.8.10 (default, Jun  2 2021, 10:49:15) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-84-generic-x86_64-with-glibc2.29', 'event': 'created'}\n",
      "03/13/2023 13:26:40 - INFO - gensim.topic_coherence.probability_estimation -   using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "03/13/2023 13:26:40 - INFO - gensim.topic_coherence.text_analysis -   1 batches submitted to accumulate stats from 64 documents (265079 virtual)\n",
      "03/13/2023 13:26:40 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 13:26:40 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 13:26:40 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 13:26:40 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 13:26:40 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 13:26:40 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 13:26:40 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 13:26:40 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 13:26:40 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 13:26:40 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 13:26:40 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 13:26:40 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   7 accumulators retrieved from output queue\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   accumulated word occurrence stats for 265079 virtual documents\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.probability_estimation -   using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   1 batches submitted to accumulate stats from 64 documents (267079 virtual)\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 13:26:44 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 13:26:46 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 13:26:46 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 13:26:46 - INFO - gensim.topic_coherence.text_analysis -   7 accumulators retrieved from output queue\n",
      "03/13/2023 13:26:46 - INFO - gensim.topic_coherence.text_analysis -   accumulated word occurrence stats for 267079 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "td: 0.88 npmi: 0.1707401858913684 cv: 0.8171689137422243\n",
      "Topics: {0: [('arsenal', 0.014460368851943201), ('club', 0.014444846365829746), ('striker', 0.010783879796568582), ('premiership', 0.010516905369054126), ('ranger', 0.009578619944874828), ('chelsea', 0.009530277550693925), ('liverpool', 0.009395257187115393), ('game', 0.008595800067009485), ('goal', 0.0081852760763205), ('player', 0.007633198158852465)], 1: [('blog', 0.02113289606071728), ('patent', 0.018918494107578388), ('search', 0.01339053671345062), ('software', 0.00987051070448693), ('domain', 0.00963868105062846), ('web', 0.008168881878505134), ('user', 0.008144586215971014), ('engine', 0.006781821569538562), ('invention', 0.006444745189562567), ('site', 0.006275600304821727)], 2: [('tory', 0.014768007981511415), ('labour', 0.01417239206717134), ('election', 0.012841207434835921), ('party', 0.009624858360730442), ('government', 0.006491542764338431), ('chancellor', 0.006017319270945101), ('tax', 0.00581773892812574), ('conservative', 0.005625400122680979), ('dem', 0.005418210804857282), ('minister', 0.004714041155342018)], 3: [('economic', 0.010815077155002857), ('economy', 0.009001629057528224), ('deficit', 0.008857496688449202), ('country', 0.008008194632164492), ('budget', 0.007607475211541107), ('debt', 0.006415642090344813), ('aid', 0.006308089832255005), ('government', 0.00576644374477057), ('growth', 0.005431094138016664), ('spending', 0.005130530512121915)], 4: [('band', 0.016317558185537567), ('album', 0.014435021298353308), ('music', 0.013788768121974385), ('chart', 0.01252754645763632), ('song', 0.009334483587406846), ('singer', 0.008575438578737998), ('concert', 0.008060501810303095), ('festival', 0.007754368430438743), ('musical', 0.006595733167793088), ('guitarist', 0.006404653173559847)], 5: [('indoor', 0.0248762632684249), ('marathon', 0.020270159504140014), ('race', 0.019222348171524357), ('championship', 0.015770901552580992), ('medal', 0.014461803609248826), ('olympic', 0.01379479472912649), ('athlete', 0.013050179681861661), ('win', 0.011760122658749806), ('world', 0.009553535774534463), ('gold', 0.009064228389928833)], 6: [('game', 0.018761843616799792), ('console', 0.012563247063462497), ('gamer', 0.01127317379652383), ('psp', 0.008453325146742682), ('piracy', 0.007807309451835738), ('music', 0.006732815606029879), ('file', 0.006522891096573976), ('peer', 0.006222540494946978), ('film', 0.005964851336926585), ('pirate', 0.005871105520532873)], 7: [('award', 0.03217282240959629), ('film', 0.028692589677450427), ('nomination', 0.017811565702994924), ('good', 0.01586190157133043), ('aviator', 0.014566994910435742), ('oscar', 0.014509518114862388), ('actor', 0.012528981894137719), ('nominate', 0.01235684756323521), ('category', 0.012074409991576019), ('prize', 0.011296642458308567)], 8: [('rugby', 0.011908947833251802), ('game', 0.01099873801812381), ('squad', 0.008908525121745062), ('injury', 0.008647031284574629), ('nation', 0.008325495746952929), ('play', 0.007912722277687979), ('wale', 0.007548060428162165), ('match', 0.00748638748592472), ('flanker', 0.007402335900281405), ('side', 0.007315539584010835)], 9: [('iaaf', 0.05495521213075087), ('dope', 0.033068840534255295), ('athlete', 0.026134705952782968), ('drug', 0.025926895062693685), ('thanou', 0.025038769607380603), ('sprinter', 0.02287257884940966), ('test', 0.01981601244162109), ('greek', 0.015961694203281356), ('ban', 0.014777535204552683), ('substance', 0.010655787194106228)], 10: [('economy', 0.017238905644850068), ('growth', 0.016604126245978602), ('rate', 0.015265475393230801), ('dollar', 0.0120917142898889), ('economist', 0.011851463481205303), ('rise', 0.011658601080667193), ('export', 0.011577633280944142), ('economic', 0.010637604018622094), ('inflation', 0.008992647339416251), ('price', 0.008769650916462727)], 11: [('fraud', 0.012067627521890032), ('firm', 0.010101096371033362), ('accounting', 0.009226744179914878), ('company', 0.008707285312826295), ('prosecutor', 0.007966200189341854), ('shareholder', 0.0061322970636044465), ('bank', 0.005842003152495873), ('scandal', 0.005753541161539518), ('guilty', 0.005468638727849933), ('settlement', 0.005401489188241941)], 12: [('show', 0.014292558981351995), ('viewer', 0.008915312506839055), ('contestant', 0.008490915210229535), ('episode', 0.008331145730412479), ('audience', 0.008275797465459547), ('celebrity', 0.008143325298116838), ('programme', 0.00647546190260022), ('series', 0.005800233777327814), ('rating', 0.005742682454027376), ('brother', 0.005391062420974569)], 13: [('virus', 0.028061218415625488), ('spam', 0.0248879034624946), ('mail', 0.019419029024579402), ('spyware', 0.019168702566864395), ('user', 0.015919293773146926), ('program', 0.01574115147450926), ('spammer', 0.01413775948856034), ('site', 0.012483049993538452), ('software', 0.010733732749672155), ('malicious', 0.010710388093131872)], 14: [('mobile', 0.0147101774196351), ('broadband', 0.01073351661826013), ('phone', 0.009900494855165231), ('technology', 0.008814896104838143), ('device', 0.007928744382354505), ('gadget', 0.007818587651186586), ('user', 0.007475637526845651), ('computer', 0.006173695497848514), ('digital', 0.006155936605321936), ('music', 0.0061123259559445415)], 15: [('oil', 0.0374134084165252), ('russian', 0.02010884855725823), ('gazprom', 0.019709492032600084), ('rosneft', 0.016044820347070353), ('gas', 0.01521752091619707), ('crude', 0.015077187940458408), ('barrel', 0.011700888562667195), ('auction', 0.009278086199360377), ('price', 0.008485190931520158), ('bankruptcy', 0.008073467326827845)], 16: [('police', 0.008744481962273665), ('terror', 0.0076926185708791235), ('law', 0.006862274897069348), ('detainee', 0.006761478519861771), ('lord', 0.006528403822973745), ('hunt', 0.006105975155354518), ('detention', 0.005718761124902957), ('tory', 0.005497970684468994), ('detain', 0.00537273974314631), ('hunting', 0.005051145296501193)], 17: [('seed', 0.03130530257160868), ('roddick', 0.017920785000053223), ('tennis', 0.01624499659788857), ('davenport', 0.015610391179844259), ('federer', 0.015601260138114302), ('match', 0.014506356593635), ('open', 0.013585354113723497), ('australian', 0.0134636987898233), ('win', 0.012401810979720734), ('beat', 0.012366523452308716)], 18: [('profit', 0.009396447643664565), ('share', 0.009341593022257547), ('shareholder', 0.007931766844137706), ('airline', 0.007709773945090281), ('takeover', 0.007392441518588644), ('firm', 0.007288293917061737), ('company', 0.007219533357373773), ('sale', 0.007011954226242135), ('market', 0.006566417171513959), ('stake', 0.005829961985447113)], 19: [('film', 0.043129696296872355), ('actor', 0.01283548391943944), ('festival', 0.011829212954602979), ('star', 0.01151099435382536), ('movie', 0.010831879384694338), ('comedy', 0.009613007461187489), ('sequel', 0.008459440494413852), ('cinema', 0.005791951030955785), ('taking', 0.005646439380917105), ('studio', 0.005597281080446409)]}\n"
     ]
    }
   ],
   "source": [
    "td_score, cv_score, npmi_score = tm.evaluate()\n",
    "\n",
    "print(f'td: {td_score} npmi: {npmi_score} cv: {cv_score}')\n",
    "\n",
    "topics = tm.get_topics()\n",
    "print(f'Topics: {topics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3957706177.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[17], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    td: 0.865 npmi: 0.18230689973338862 cv: 0.8190428139031213\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".raymond",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
