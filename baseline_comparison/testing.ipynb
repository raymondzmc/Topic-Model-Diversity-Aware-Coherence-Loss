{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/felipe/.raymond/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from baselines.cetopictm import CETopicTM\n",
    "\n",
    "from utils import prepare_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, sentences = prepare_dataset('bbc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize CETopicTM with num_topics=5, embedding=princeton-nlp/unsup-simcse-bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 252/252 [00:00<00:00, 120kB/s]\n",
      "Downloading: 100%|██████████| 697/697 [00:00<00:00, 346kB/s]\n",
      "Downloading: 100%|██████████| 232k/232k [00:00<00:00, 1.02MB/s]\n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 53.8kB/s]\n",
      "Downloading: 100%|██████████| 438M/438M [00:04<00:00, 100MB/s]  \n"
     ]
    }
   ],
   "source": [
    "tm = CETopicTM(dataset=dataset, \n",
    "               topic_model='cetopic', \n",
    "               num_topics=5, \n",
    "               dim_size=5, \n",
    "               word_select_method='tfidf_idfi',\n",
    "               embedding='princeton-nlp/unsup-simcse-bert-base-uncased', \n",
    "               seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/13/2023 11:58:34 - INFO - gensim.corpora.dictionary -   adding document #0 to Dictionary<0 unique tokens: []>\n",
      "03/13/2023 11:58:34 - INFO - gensim.corpora.dictionary -   built Dictionary<2949 unique tokens: ['abandon', 'ability', 'absence', 'absolute', 'absolutely']...> from 5 documents (total 267259 corpus positions)\n",
      "03/13/2023 11:58:34 - INFO - gensim.utils -   Dictionary lifecycle event {'msg': \"built Dictionary<2949 unique tokens: ['abandon', 'ability', 'absence', 'absolute', 'absolutely']...> from 5 documents (total 267259 corpus positions)\", 'datetime': '2023-03-13T11:58:34.468038', 'gensim': '4.2.0', 'python': '3.8.10 (default, Jun  2 2021, 10:49:15) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-84-generic-x86_64-with-glibc2.29', 'event': 'created'}\n",
      "03/13/2023 11:58:34 - INFO - gensim.topic_coherence.probability_estimation -   using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Using TFIDF_IDFi ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/13/2023 11:58:34 - INFO - gensim.topic_coherence.text_analysis -   1 batches submitted to accumulate stats from 64 documents (266714 virtual)\n",
      "03/13/2023 11:58:34 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 11:58:34 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 11:58:34 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 11:58:34 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 11:58:34 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 11:58:34 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 11:58:34 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 11:58:34 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 11:58:34 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 11:58:34 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 11:58:34 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 11:58:34 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   7 accumulators retrieved from output queue\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   accumulated word occurrence stats for 266714 virtual documents\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.probability_estimation -   using ParallelWordOccurrenceAccumulator<processes=7, batch_size=64> to estimate probabilities from sliding windows\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   1 batches submitted to accumulate stats from 64 documents (267214 virtual)\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 11:58:37 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 11:58:39 - INFO - gensim.topic_coherence.text_analysis -   serializing accumulator to return to master...\n",
      "03/13/2023 11:58:39 - INFO - gensim.topic_coherence.text_analysis -   accumulator serialized\n",
      "03/13/2023 11:58:39 - INFO - gensim.topic_coherence.text_analysis -   7 accumulators retrieved from output queue\n",
      "03/13/2023 11:58:39 - INFO - gensim.topic_coherence.text_analysis -   accumulated word occurrence stats for 267214 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "td: 0.96 npmi: 0.13600248148864658 cv: 0.7631635708113669\n",
      "Topics: {0: [('film', 0.018127925220013275), ('award', 0.010591982787451293), ('good', 0.00782822655178071), ('star', 0.007399484051879445), ('show', 0.006521818474769367), ('comedy', 0.006494837925537065), ('actor', 0.006423863608034273), ('festival', 0.006376403837871203), ('band', 0.006296840137526808), ('music', 0.006228965645082789)], 1: [('win', 0.010305589011457022), ('game', 0.00926996192380675), ('play', 0.009024914465932208), ('player', 0.007697761761125326), ('match', 0.00716945418566558), ('team', 0.00634053723959394), ('final', 0.005784221259588427), ('injury', 0.005622748421869439), ('side', 0.005581698185495161), ('club', 0.0052905750769323585)], 2: [('company', 0.006511418431649697), ('economy', 0.006301870744568246), ('firm', 0.006063074064948503), ('market', 0.005694122952948656), ('share', 0.005390149424691151), ('growth', 0.005351312370443902), ('rise', 0.005345459546148427), ('sale', 0.005235670280908099), ('oil', 0.005134212007642697), ('economic', 0.004904340300969712)], 3: [('election', 0.010005073414484943), ('labour', 0.009708661588600849), ('tory', 0.008404123169875832), ('party', 0.007237394947734096), ('government', 0.00661422692267681), ('plan', 0.004336431780811438), ('tax', 0.00395621667673398), ('minister', 0.003822802003639828), ('leader', 0.003582964524293288), ('pension', 0.0035396691755619617)], 4: [('mobile', 0.006814685260148373), ('software', 0.006314171511804886), ('game', 0.006289686608385869), ('technology', 0.005873074570399824), ('computer', 0.005793866074798489), ('music', 0.005769214390593592), ('phone', 0.005762701502144569), ('broadband', 0.005345979015837502), ('user', 0.00523936197897771), ('download', 0.004858016461109119)]}\n"
     ]
    }
   ],
   "source": [
    "tm.train()\n",
    "td_score, cv_score, npmi_score = tm.evaluate()\n",
    "print(f'td: {td_score} npmi: {npmi_score} cv: {cv_score}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics: {0: [('film', 0.018127925220013275), ('award', 0.010591982787451293), ('good', 0.00782822655178071), ('star', 0.007399484051879445), ('show', 0.006521818474769367), ('comedy', 0.006494837925537065), ('actor', 0.006423863608034273), ('festival', 0.006376403837871203), ('band', 0.006296840137526808), ('music', 0.006228965645082789)], 1: [('win', 0.010305589011457022), ('game', 0.00926996192380675), ('play', 0.009024914465932208), ('player', 0.007697761761125326), ('match', 0.00716945418566558), ('team', 0.00634053723959394), ('final', 0.005784221259588427), ('injury', 0.005622748421869439), ('side', 0.005581698185495161), ('club', 0.0052905750769323585)], 2: [('company', 0.006511418431649697), ('economy', 0.006301870744568246), ('firm', 0.006063074064948503), ('market', 0.005694122952948656), ('share', 0.005390149424691151), ('growth', 0.005351312370443902), ('rise', 0.005345459546148427), ('sale', 0.005235670280908099), ('oil', 0.005134212007642697), ('economic', 0.004904340300969712)], 3: [('election', 0.010005073414484943), ('labour', 0.009708661588600849), ('tory', 0.008404123169875832), ('party', 0.007237394947734096), ('government', 0.00661422692267681), ('plan', 0.004336431780811438), ('tax', 0.00395621667673398), ('minister', 0.003822802003639828), ('leader', 0.003582964524293288), ('pension', 0.0035396691755619617)], 4: [('mobile', 0.006814685260148373), ('software', 0.006314171511804886), ('game', 0.006289686608385869), ('technology', 0.005873074570399824), ('computer', 0.005793866074798489), ('music', 0.005769214390593592), ('phone', 0.005762701502144569), ('broadband', 0.005345979015837502), ('user', 0.00523936197897771), ('download', 0.004858016461109119)]}\n"
     ]
    }
   ],
   "source": [
    "topics = tm.get_topics()\n",
    "print(f'Topics: {topics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".raymond",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
